#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import json
import glob
import re

def find_chinese_files():
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã‹ã‚‰ä¸­å›½èªã‚’å«ã‚€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢"""
    
    # ä¸­å›½èªã‚’å«ã‚€å¯èƒ½æ€§ã®ã‚ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­
    target_extensions = ['.json', '.py', '.txt', '.md', '.html', '.js', '.css', '.yml', '.yaml']
    
    # é™¤å¤–ã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆæ¤œç´¢å¯¾è±¡å¤–ï¼‰
    exclude_dirs = {
        '.git', '__pycache__', '.pytest_cache', '.serena', 'node_modules',
        'agent_backup_*', '.vscode', '.idea'
    }
    
    # é™¤å¤–ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆæ—¢ã«å‡¦ç†æ¸ˆã¿ã¾ãŸã¯ç„¡é–¢ä¿‚ï¼‰
    exclude_files = {
        'maze_place_names.json',
        'maze_localization_analysis.json', 
        'place_names_translation.json',
        'extract_place_names.py',
        'check_maze_localization.py',
        'localize_maze.py',
        'localize_agents_safe.py',
        'find_chinese_files.py'
    }
    
    # ä¸­å›½èªæ–‡å­—ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
    chinese_pattern = re.compile(r'[\u4e00-\u9fff]+')
    
    results = {
        'files_with_chinese': [],
        'summary': {
            'total_files_scanned': 0,
            'files_with_chinese_count': 0,
            'by_extension': {}
        }
    }
    
    def should_exclude_dir(dir_path):
        """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’é™¤å¤–ã™ã¹ãã‹ãƒã‚§ãƒƒã‚¯"""
        dir_name = os.path.basename(dir_path)
        if dir_name in exclude_dirs:
            return True
        # agent_backup_* ãƒ‘ã‚¿ãƒ¼ãƒ³
        if dir_name.startswith('agent_backup_'):
            return True
        return False
    
    def should_exclude_file(file_path):
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é™¤å¤–ã™ã¹ãã‹ãƒã‚§ãƒƒã‚¯"""
        file_name = os.path.basename(file_path)
        return file_name in exclude_files
    
    def find_chinese_in_text(text, file_path):
        """ãƒ†ã‚­ã‚¹ãƒˆå†…ã®ä¸­å›½èªã‚’æ¤œç´¢"""
        chinese_matches = []
        lines = text.split('\n')
        
        for line_num, line in enumerate(lines, 1):
            matches = chinese_pattern.findall(line.strip())
            if matches:
                chinese_matches.append({
                    'line': line_num,
                    'content': line.strip()[:100],  # æœ€åˆã®100æ–‡å­—ã®ã¿
                    'chinese_words': matches
                })
        
        return chinese_matches
    
    def scan_file(file_path):
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—ã¦ä¸­å›½èªã‚’æ¤œç´¢"""
        if should_exclude_file(file_path):
            return None
        
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # ä¸­å›½èªã‚’æ¤œç´¢
            chinese_matches = find_chinese_in_text(content, file_path)
            
            if chinese_matches:
                return {
                    'file_path': file_path,
                    'relative_path': os.path.relpath(file_path),
                    'extension': os.path.splitext(file_path)[1],
                    'file_size': os.path.getsize(file_path),
                    'chinese_count': len(chinese_matches),
                    'matches': chinese_matches[:5]  # æœ€åˆã®5å€‹ã®ãƒãƒƒãƒã®ã¿ä¿å­˜
                }
        
        except UnicodeDecodeError:
            # ãƒã‚¤ãƒŠãƒªãƒ•ã‚¡ã‚¤ãƒ«ã¯ç„¡è¦–
            return None
        except Exception as e:
            print(f"âš ï¸ {file_path}: èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ ({e})")
            return None
        
        return None
    
    print("ğŸ” ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã‹ã‚‰ä¸­å›½èªã‚’å«ã‚€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢ä¸­...")
    
    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‹ã‚‰å†å¸°çš„ã«ã‚¹ã‚­ãƒ£ãƒ³
    for root, dirs, files in os.walk('.'):
        # é™¤å¤–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        dirs[:] = [d for d in dirs if not should_exclude_dir(os.path.join(root, d))]
        
        for file in files:
            file_path = os.path.join(root, file)
            file_ext = os.path.splitext(file)[1].lower()
            
            # å¯¾è±¡æ‹¡å¼µå­ã®ã¿å‡¦ç†
            if file_ext in target_extensions:
                results['summary']['total_files_scanned'] += 1
                
                chinese_info = scan_file(file_path)
                if chinese_info:
                    results['files_with_chinese'].append(chinese_info)
                    results['summary']['files_with_chinese_count'] += 1
                    
                    # æ‹¡å¼µå­åˆ¥çµ±è¨ˆ
                    ext = chinese_info['extension']
                    if ext not in results['summary']['by_extension']:
                        results['summary']['by_extension'][ext] = 0
                    results['summary']['by_extension'][ext] += 1
    
    # çµæœè¡¨ç¤º
    print(f"âœ… ã‚¹ã‚­ãƒ£ãƒ³å®Œäº†")
    print(f"\nğŸ“Š æ¤œç´¢çµæœ:")
    print(f"  - ã‚¹ã‚­ãƒ£ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {results['summary']['total_files_scanned']}")
    print(f"  - ä¸­å›½èªå«æœ‰ãƒ•ã‚¡ã‚¤ãƒ«: {results['summary']['files_with_chinese_count']}")
    
    if results['summary']['by_extension']:
        print(f"\nğŸ“‚ æ‹¡å¼µå­åˆ¥çµ±è¨ˆ:")
        for ext, count in sorted(results['summary']['by_extension'].items()):
            print(f"  - {ext}: {count}ãƒ•ã‚¡ã‚¤ãƒ«")
    
    if results['files_with_chinese']:
        print(f"\nğŸ” ä¸­å›½èªã‚’å«ã‚€ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§:")
        
        # å„ªå…ˆåº¦ã§ã‚½ãƒ¼ãƒˆï¼ˆJSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’å„ªå…ˆï¼‰
        priority_order = {'.json': 1, '.py': 2, '.html': 3, '.txt': 4, '.md': 5}
        sorted_files = sorted(
            results['files_with_chinese'],
            key=lambda x: (priority_order.get(x['extension'], 10), -x['chinese_count'])
        )
        
        for i, file_info in enumerate(sorted_files, 1):
            print(f"\n  {i:2d}. {file_info['relative_path']}")
            print(f"      æ‹¡å¼µå­: {file_info['extension']}")
            print(f"      ä¸­å›½èªç®‡æ‰€: {file_info['chinese_count']}")
            print(f"      ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_info['file_size']} bytes")
            
            # ã‚µãƒ³ãƒ—ãƒ«ã‚’è¡¨ç¤º
            if file_info['matches']:
                print(f"      ã‚µãƒ³ãƒ—ãƒ«:")
                for match in file_info['matches'][:3]:
                    print(f"        L{match['line']}: {match['content']}")
    
    # çµæœã‚’JSONã§ä¿å­˜
    output_file = "chinese_files_scan.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ è©³ç´°çµæœã‚’ {output_file} ã«ä¿å­˜ã—ã¾ã—ãŸ")
    
    # ç¿»è¨³æ¨å¥¨ãƒ•ã‚¡ã‚¤ãƒ«ã®ç‰¹å®š
    translation_candidates = []
    for file_info in results['files_with_chinese']:
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚„ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å„ªå…ˆ
        if (file_info['extension'] in ['.json', '.py'] and 
            file_info['chinese_count'] >= 5):
            translation_candidates.append(file_info)
    
    if translation_candidates:
        print(f"\nğŸ¯ ç¿»è¨³æ¨å¥¨ãƒ•ã‚¡ã‚¤ãƒ« ({len(translation_candidates)}ä»¶):")
        for candidate in translation_candidates:
            print(f"  âœ… {candidate['relative_path']} ({candidate['chinese_count']}ç®‡æ‰€)")
    else:
        print(f"\nâœ… è¿½åŠ ã®ç¿»è¨³ãŒå¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
    
    return results

if __name__ == "__main__":
    find_chinese_files()